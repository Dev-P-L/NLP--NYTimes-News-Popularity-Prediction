HeadlineWordsTest = tail(HeadlineWords, nrow(NewsTest))
# Before building the model, we want to add back
# the original variables from our datasets.
HeadlineWordsTrain$Popular = NewsTrain$Popular
HeadlineWordsTrain$WordCount = NewsTrain$WordCount
HeadlineWordsTrain$Weekday = NewsTrain$Weekday
HeadlineWordsTrain$NewsDesk = NewsTrain$NewsDesk
HeadlineWordsTrain$SectionName = NewsTrain$SectionName
HeadlineWordsTrain$SubsectionName = NewsTrain$SubsectionName
HeadlineWordsTest$Popular = NewsTest$Popular
HeadlineWordsTest$WordCount = NewsTest$WordCount
HeadlineWordsTest$NewsDesk = NewsTest$NewsDesk
HeadlineWordsTest$Weekday = NewsTest$Weekday
HeadlineWordsTest$SectionName = NewsTest$SectionName
HeadlineWordsTest$SubsectionName = NewsTest$SubsectionName
# Create simple model taking into consideration only word count
fit = train(Popular ~ ., data=HeadlineWordsTrain, method = "svmRadialCost",
tuneLength = 3)
## Objective of the Project
# https://www.kaggle.com/c/3-071x-the-analytics-edge-competition-spring-203/overview
# What makes online news articles popular?
# Newspapers and online news aggregators like Google News
# need to understand which news articles will be the most popular,
# so that they can prioritize the order in which stories appear.
# In this competition, you will predict the popularity
# of a set of New York Times blog articles
# from the time period September 2014-December 2014.
# Many blog articles are published each day,
# and the New York Times has to decide which articles should be featured.
# In this competition, we challenge you to develop an analytics model
# that will help the New York Times understand
# the features of a blog post that make it popular.
# The evaluation metric for this competition is AUC.
# The AUC, which we described in Unit 3 when we taught logistic regression,
# is a commonly used evaluation metric for binary classification problems like this one.
# The interpretation is that given a random positive observation and negative observation,
# the AUC gives the proportion of the time you guess which is which correctly.
# It is less affected by sample balance than accuracy.
# A perfect model will score an AUC of 1,
# while random guessing will score an AUC of around 0.5.
##############################################################################
## Software requirements
# In this project Predicting News Success, code is written down in RMarkdown.
# Code is contained in file NLP_Script.Rmd, which can be found in my
# GitHub repository ...
# The version of R that I use is
# R version 3.5.1 (2018-07-02) -- "Feather Spray"
# Copyright (C) 2018 The R Foundation for Statistical Computing
# Platform: x86_64-w64-mingw32/x64 (64-bit)
# The operating system on my PC is Windows 10.
# Report.Rmd has been knitted to HTML in
# RStudio Version 1.1.456 - ? 2009-2018 RStudio, Inc., and this produces
# document Report.html, which can also be found in the same GitHub
# repository.For readers' convenience, Report.html has also
# been converted into Report.pdf and Report.docx, which once again
# can be found in the GitHub repository.
# I cannot guarantee NLP_Script running in other environments.
##############################################################################
## CLEANING USER INTERFACE FOR RAM MANAGEMENT
# Clearing plots, cleaning workspace and console.
invisible(if(!is.null(dev.list())) dev.off())
rm(list=ls())
cat("\014")
# The function invisible() is used to prevent technical information showing up
# in Report.Rmd and, most important, in Report.pdf. That piece of information
# would have no operational impact.
#################################################################################
## LOADING PACKAGES
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(kableExtra)) install.packages("kableExtra", repos = "http://cran.us.r-project.org")
if(!require(tm)) install.packages("tm", repos = "http://cran.us.r-project.org")
# P.S. kableExtra helps reshape tables.
#################################################################################
ds <- read.csv("https://raw.githubusercontent.com/gdwangh/edxTheAnalyticsEdge/master/kaggleCompetition/NYTimesBlogTrain.csv")
ds <- ds %>% mutate(Popular =
factor(gsub(1, "Popular", gsub(0, "Unpopular", Popular))))
## Exploratory Data Analysis
head(ds$NewsDesk)
#split the data into train and test
y <- ds$Popular
test_index <- createDataPartition(y, times = 1, p = 0.3, list = FALSE)
NewsTrain <- ds %>% slice(-test_index)
NewsTest <- ds %>% slice(test_index)
# Convert the date/time
NewsTrain$PubDate = strptime(NewsTrain$PubDate, "%Y-%m-%d %H:%M:%S")
NewsTest$PubDate = strptime(NewsTest$PubDate, "%Y-%m-%d %H:%M:%S")
# Add a variable to our datasets called "Weekday" that contains
# the day of the week that the article was published
# (0 = Sunday, 1 = Monday, etc.)
NewsTrain$Weekday = NewsTrain$PubDate$wday
NewsTest$Weekday = NewsTest$PubDate$wday
# Create simple model taking into consideration only word count
fit = train(Popular ~ WordCount, data = NewsTrain, method = "svmRadialCost",
tuneLength = 1)
# compute the accuracy on training set
fitted <- predict(fit)
mean(fitted == NewsTrain$Popular)
# Make Predictions on test data
pred <- predict(fit, newdata = NewsTest)
# compute the accuracy on test set
mean(pred == NewsTest$Popular)
# Standard pre-processing steps
CorpusHeadline = VCorpus(VectorSource(c(NewsTrain$Headline, NewsTest$Headline)))
CorpusHeadline = tm_map(CorpusHeadline, content_transformer(tolower))
CorpusHeadline = tm_map(CorpusHeadline, removePunctuation)
CorpusHeadline = tm_map(CorpusHeadline, removeWords, stopwords("english"))
CorpusHeadline = tm_map(CorpusHeadline, stemDocument)
# Convert corpus to a DocumentTermMatrix,
# remove sparse terms, and turn it into a data frame.
dtm = DocumentTermMatrix(CorpusHeadline)
# Select the threshold 99% to remove sparse terms.
sparse = removeSparseTerms(dtm, 0.99)
HeadlineWords = as.data.frame(as.matrix(sparse))
colnames(HeadlineWords) = make.names(colnames(HeadlineWords))
HeadlineWordsTrain = head(HeadlineWords, nrow(NewsTrain))
HeadlineWordsTest = tail(HeadlineWords, nrow(NewsTest))
# Before building the model, we want to add back
# the original variables from our datasets.
HeadlineWordsTrain$Popular = NewsTrain$Popular
HeadlineWordsTrain$WordCount = NewsTrain$WordCount
HeadlineWordsTrain$Weekday = NewsTrain$Weekday
HeadlineWordsTrain$NewsDesk = NewsTrain$NewsDesk
HeadlineWordsTrain$SectionName = NewsTrain$SectionName
HeadlineWordsTrain$SubsectionName = NewsTrain$SubsectionName
HeadlineWordsTest$Popular = NewsTest$Popular
HeadlineWordsTest$WordCount = NewsTest$WordCount
HeadlineWordsTest$NewsDesk = NewsTest$NewsDesk
HeadlineWordsTest$Weekday = NewsTest$Weekday
HeadlineWordsTest$SectionName = NewsTest$SectionName
HeadlineWordsTest$SubsectionName = NewsTest$SubsectionName
# Create simple model taking into consideration only word count
fit = train(Popular ~ ., data=HeadlineWordsTrain, method = "svmRadialCost",
tuneLength = 1)
# compute the accuracy on training set
fitted <- predict(fit)
mean(fitted == NewsTrain$Popular)
# Make Predictions on test data
pred <- predict(fit, newdata = HeadlineWordsTest)
# compute the accuracy on test set
mean(pred == NewsTest$Popular)
##############################################
## Objective of the Project
# https://www.kaggle.com/c/3-071x-the-analytics-edge-competition-spring-203/overview
# What makes online news articles popular?
# Newspapers and online news aggregators like Google News
# need to understand which news articles will be the most popular,
# so that they can prioritize the order in which stories appear.
# In this competition, you will predict the popularity
# of a set of New York Times blog articles
# from the time period September 2014-December 2014.
# Many blog articles are published each day,
# and the New York Times has to decide which articles should be featured.
# In this competition, we challenge you to develop an analytics model
# that will help the New York Times understand
# the features of a blog post that make it popular.
# The evaluation metric for this competition is AUC.
# The AUC, which we described in Unit 3 when we taught logistic regression,
# is a commonly used evaluation metric for binary classification problems like this one.
# The interpretation is that given a random positive observation and negative observation,
# the AUC gives the proportion of the time you guess which is which correctly.
# It is less affected by sample balance than accuracy.
# A perfect model will score an AUC of 1,
# while random guessing will score an AUC of around 0.5.
##############################################################################
## Software requirements
# In this project Predicting News Success, code is written down in RMarkdown.
# Code is contained in file NLP_Script.Rmd, which can be found in my
# GitHub repository ...
# The version of R that I use is
# R version 3.5.1 (2018-07-02) -- "Feather Spray"
# Copyright (C) 2018 The R Foundation for Statistical Computing
# Platform: x86_64-w64-mingw32/x64 (64-bit)
# The operating system on my PC is Windows 10.
# Report.Rmd has been knitted to HTML in
# RStudio Version 1.1.456 - ? 2009-2018 RStudio, Inc., and this produces
# document Report.html, which can also be found in the same GitHub
# repository.For readers' convenience, Report.html has also
# been converted into Report.pdf and Report.docx, which once again
# can be found in the GitHub repository.
# I cannot guarantee NLP_Script running in other environments.
##############################################################################
## CLEANING USER INTERFACE FOR RAM MANAGEMENT
# Clearing plots, cleaning workspace and console.
invisible(if(!is.null(dev.list())) dev.off())
rm(list=ls())
cat("\014")
# The function invisible() is used to prevent technical information showing up
# in Report.Rmd and, most important, in Report.pdf. That piece of information
# would have no operational impact.
#################################################################################
## LOADING PACKAGES
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(kableExtra)) install.packages("kableExtra", repos = "http://cran.us.r-project.org")
if(!require(tm)) install.packages("tm", repos = "http://cran.us.r-project.org")
# P.S. kableExtra helps reshape tables.
#################################################################################
ds <- read.csv("https://raw.githubusercontent.com/gdwangh/edxTheAnalyticsEdge/master/kaggleCompetition/NYTimesBlogTrain.csv")
ds <- ds %>% mutate(Popular =
factor(gsub(1, "Popular", gsub(0, "Unpopular", Popular))))
## Exploratory Data Analysis
head(ds$NewsDesk)
#split the data into train and test
y <- ds$Popular
test_index <- createDataPartition(y, times = 1, p = 0.3, list = FALSE)
NewsTrain <- ds %>% slice(-test_index)
NewsTest <- ds %>% slice(test_index)
# Convert the date/time
NewsTrain$PubDate = strptime(NewsTrain$PubDate, "%Y-%m-%d %H:%M:%S")
NewsTest$PubDate = strptime(NewsTest$PubDate, "%Y-%m-%d %H:%M:%S")
# Add a variable to our datasets called "Weekday" that contains
# the day of the week that the article was published
# (0 = Sunday, 1 = Monday, etc.)
NewsTrain$Weekday = NewsTrain$PubDate$wday
NewsTest$Weekday = NewsTest$PubDate$wday
# Create simple model taking into consideration only word count
fit = train(Popular ~ ., data = NewsTrain, method = "glm",
tuneLength = 1)
# compute the accuracy on training set
fitted <- predict(fit)
mean(fitted == NewsTrain$Popular)
# Make Predictions on test data
pred <- predict(fit, newdata = NewsTest)
# compute the accuracy on test set
mean(pred == NewsTest$Popular)
# Standard pre-processing steps
CorpusHeadline = VCorpus(VectorSource(c(NewsTrain$Headline, NewsTest$Headline)))
CorpusHeadline = tm_map(CorpusHeadline, content_transformer(tolower))
CorpusHeadline = tm_map(CorpusHeadline, removePunctuation)
CorpusHeadline = tm_map(CorpusHeadline, removeWords, stopwords("english"))
CorpusHeadline = tm_map(CorpusHeadline, stemDocument)
# Convert corpus to a DocumentTermMatrix,
# remove sparse terms, and turn it into a data frame.
dtm = DocumentTermMatrix(CorpusHeadline)
# Select the threshold 99% to remove sparse terms.
sparse = removeSparseTerms(dtm, 0.99)
HeadlineWords = as.data.frame(as.matrix(sparse))
colnames(HeadlineWords) = make.names(colnames(HeadlineWords))
HeadlineWordsTrain = head(HeadlineWords, nrow(NewsTrain))
HeadlineWordsTest = tail(HeadlineWords, nrow(NewsTest))
# Before building the model, we want to add back
# the original variables from our datasets.
HeadlineWordsTrain$Popular = NewsTrain$Popular
HeadlineWordsTrain$WordCount = NewsTrain$WordCount
HeadlineWordsTrain$Weekday = NewsTrain$Weekday
HeadlineWordsTrain$NewsDesk = NewsTrain$NewsDesk
HeadlineWordsTrain$SectionName = NewsTrain$SectionName
HeadlineWordsTrain$SubsectionName = NewsTrain$SubsectionName
HeadlineWordsTest$Popular = NewsTest$Popular
HeadlineWordsTest$WordCount = NewsTest$WordCount
HeadlineWordsTest$NewsDesk = NewsTest$NewsDesk
HeadlineWordsTest$Weekday = NewsTest$Weekday
HeadlineWordsTest$SectionName = NewsTest$SectionName
HeadlineWordsTest$SubsectionName = NewsTest$SubsectionName
# Create simple model taking into consideration only word count
fit = train(Popular ~ ., data=HeadlineWordsTrain, method = "glm",
tuneLength = 1)
# compute the accuracy on training set
fitted <- predict(fit)
mean(fitted == NewsTrain$Popular)
# Make Predictions on test data
pred <- predict(fit, newdata = HeadlineWordsTest)
# compute the accuracy on test set
mean(pred == NewsTest$Popular)
##############################################
## Objective of the Project
# https://www.kaggle.com/c/3-071x-the-analytics-edge-competition-spring-203/overview
# What makes online news articles popular?
# Newspapers and online news aggregators like Google News
# need to understand which news articles will be the most popular,
# so that they can prioritize the order in which stories appear.
# In this competition, you will predict the popularity
# of a set of New York Times blog articles
# from the time period September 2014-December 2014.
# Many blog articles are published each day,
# and the New York Times has to decide which articles should be featured.
# In this competition, we challenge you to develop an analytics model
# that will help the New York Times understand
# the features of a blog post that make it popular.
# The evaluation metric for this competition is AUC.
# The AUC, which we described in Unit 3 when we taught logistic regression,
# is a commonly used evaluation metric for binary classification problems like this one.
# The interpretation is that given a random positive observation and negative observation,
# the AUC gives the proportion of the time you guess which is which correctly.
# It is less affected by sample balance than accuracy.
# A perfect model will score an AUC of 1,
# while random guessing will score an AUC of around 0.5.
##############################################################################
## Software requirements
# In this project Predicting News Success, code is written down in RMarkdown.
# Code is contained in file NLP_Script.Rmd, which can be found in my
# GitHub repository ...
# The version of R that I use is
# R version 3.5.1 (2018-07-02) -- "Feather Spray"
# Copyright (C) 2018 The R Foundation for Statistical Computing
# Platform: x86_64-w64-mingw32/x64 (64-bit)
# The operating system on my PC is Windows 10.
# Report.Rmd has been knitted to HTML in
# RStudio Version 1.1.456 - ? 2009-2018 RStudio, Inc., and this produces
# document Report.html, which can also be found in the same GitHub
# repository.For readers' convenience, Report.html has also
# been converted into Report.pdf and Report.docx, which once again
# can be found in the GitHub repository.
# I cannot guarantee NLP_Script running in other environments.
##############################################################################
## CLEANING USER INTERFACE FOR RAM MANAGEMENT
# Clearing plots, cleaning workspace and console.
invisible(if(!is.null(dev.list())) dev.off())
rm(list=ls())
cat("\014")
# The function invisible() is used to prevent technical information showing up
# in Report.Rmd and, most important, in Report.pdf. That piece of information
# would have no operational impact.
#################################################################################
## LOADING PACKAGES
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(kableExtra)) install.packages("kableExtra", repos = "http://cran.us.r-project.org")
if(!require(tm)) install.packages("tm", repos = "http://cran.us.r-project.org")
# P.S. kableExtra helps reshape tables.
#################################################################################
ds <- read.csv("https://raw.githubusercontent.com/gdwangh/edxTheAnalyticsEdge/master/kaggleCompetition/NYTimesBlogTrain.csv")
ds <- ds %>% mutate(Popular =
factor(gsub(1, "Popular", gsub(0, "Unpopular", Popular))))
## Exploratory Data Analysis
head(ds$NewsDesk)
#split the data into train and test
y <- ds$Popular
test_index <- createDataPartition(y, times = 1, p = 0.3, list = FALSE)
NewsTrain <- ds %>% slice(-test_index)
NewsTest <- ds %>% slice(test_index)
# Convert the date/time
NewsTrain$PubDate = strptime(NewsTrain$PubDate, "%Y-%m-%d %H:%M:%S")
NewsTest$PubDate = strptime(NewsTest$PubDate, "%Y-%m-%d %H:%M:%S")
# Add a variable to our datasets called "Weekday" that contains
# the day of the week that the article was published
# (0 = Sunday, 1 = Monday, etc.)
NewsTrain$Weekday = NewsTrain$PubDate$wday
NewsTest$Weekday = NewsTest$PubDate$wday
# Create simple model taking into consideration only word count
fit = train(Popular ~ ., data = NewsTrain, method = "glm")
# compute the accuracy on training set
fitted <- predict(fit)
mean(fitted == NewsTrain$Popular)
# Make Predictions on test data
pred <- predict(fit, newdata = NewsTest)
# compute the accuracy on test set
mean(pred == NewsTest$Popular)
# Standard pre-processing steps
CorpusHeadline = VCorpus(VectorSource(c(NewsTrain$Headline, NewsTest$Headline)))
CorpusHeadline = tm_map(CorpusHeadline, content_transformer(tolower))
CorpusHeadline = tm_map(CorpusHeadline, removePunctuation)
CorpusHeadline = tm_map(CorpusHeadline, removeWords, stopwords("english"))
CorpusHeadline = tm_map(CorpusHeadline, stemDocument)
# Convert corpus to a DocumentTermMatrix,
# remove sparse terms, and turn it into a data frame.
dtm = DocumentTermMatrix(CorpusHeadline)
# Select the threshold 99% to remove sparse terms.
sparse = removeSparseTerms(dtm, 0.99)
HeadlineWords = as.data.frame(as.matrix(sparse))
colnames(HeadlineWords) = make.names(colnames(HeadlineWords))
HeadlineWordsTrain = head(HeadlineWords, nrow(NewsTrain))
HeadlineWordsTest = tail(HeadlineWords, nrow(NewsTest))
# Before building the model, we want to add back
# the original variables from our datasets.
HeadlineWordsTrain$Popular = NewsTrain$Popular
HeadlineWordsTrain$WordCount = NewsTrain$WordCount
HeadlineWordsTrain$Weekday = NewsTrain$Weekday
HeadlineWordsTrain$NewsDesk = NewsTrain$NewsDesk
HeadlineWordsTrain$SectionName = NewsTrain$SectionName
HeadlineWordsTrain$SubsectionName = NewsTrain$SubsectionName
HeadlineWordsTest$Popular = NewsTest$Popular
HeadlineWordsTest$WordCount = NewsTest$WordCount
HeadlineWordsTest$NewsDesk = NewsTest$NewsDesk
HeadlineWordsTest$Weekday = NewsTest$Weekday
HeadlineWordsTest$SectionName = NewsTest$SectionName
HeadlineWordsTest$SubsectionName = NewsTest$SubsectionName
# Create simple model taking into consideration only word count
fit = train(Popular ~ ., data=HeadlineWordsTrain, method = "glm")
# compute the accuracy on training set
fitted <- predict(fit)
mean(fitted == NewsTrain$Popular)
# Make Predictions on test data
pred <- predict(fit, newdata = HeadlineWordsTest)
# compute the accuracy on test set
mean(pred == NewsTest$Popular)
##############################################
ds <- read.csv("https://raw.githubusercontent.com/gdwangh/edxTheAnalyticsEdge/master/kaggleCompetition/NYTimesBlogTrain.csv")
ds <- ds %>% mutate(Popular =
factor(gsub(1, "Popular", gsub(0, "Unpopular", Popular))))
sum(ds$Popular)
ds <- read.csv("https://raw.githubusercontent.com/gdwangh/edxTheAnalyticsEdge/master/kaggleCompetition/NYTimesBlogTrain.csv")
sum(ds$Popular)
sum(ds$Popular) / nrow(ds)
1/6
head(ds$NewsDesk)
colnames(ds)
head(ds$SectionName)
head(ds$SubsectionName)
head(ds$Headline)
colnames(ds)
head(ds$Snippet)
colnames(ds)
head(ds$Abstract)
head(ds$Snippet)
identical(ds$Snippet, ds$Abstract)
setdiff(ds$Snippet, ds$Abstract)
head(setdiff(ds$Snippet, ds$Abstract))
head(intersect(ds$Snippet, ds$Abstract))
tail(intersect(ds$Snippet, ds$Abstract))
length(intersect(ds$Snippet, ds$Abstract))
length(setdiff(ds$Snippet, ds$Abstract))
colnames(ds)
head(ds$PubDate)
identical(ds$Snippet, ds$Abstract)
(ds$Snippet == ds$Abstract)
v <- 1:length(ds$Snippet)
for (i in 1:length(ds$Snippet)) {
v[i] <- identical(ds$Snippet[i], ds$Abstract[i])
}
head(v)
head(v, 20)
sum(v)
i <- 1
ds$Snippet[i]
ds$Abstract[i]
i <- 1
v <- as.character(1:length(ds$Snippet))
ds$Snippet[i]
ds$Abstract[i]
head(v, 20)
v[i] <- identical(ds$Snippet[i], ds$Abstract[i])
head(v, 20)
i <- 1
v <- as.character(1:length(ds$Snippet))
v[i] <- identical(as.character(ds$Snippet[i]),
as.character(ds$Abstract[i]))
head(v, 20)
i <- 1
v <- as.character(1:length(ds$Snippet))
for (i in 1:length(ds$Snippet)) {
v[i] <- identical(as.character(ds$Snippet[i]),
as.character(ds$Abstract[i]))
}
head(v, 20)
sum(v)
as.numeric(TRUE)
as.numeric(FALSE)
sum(as.numeric(v))
sum(isna(as.numeric(v)))
sum(is.na(as.numeric(v)))
v <- as.character(1:length(ds$Snippet))
for (i in 1:length(ds$Snippet)) {
v[i] <- identical(as.character(ds$Snippet[i]),
as.character(ds$Abstract[i]))
}
head(v, 20)
sum(as.numeric(v))
sum(is.na(as.numeric(v)))
v
as.numeric(v)
for (i in 1:length(ds$Snippet)) {
v[i] <- identical(as.character(ds$Snippet[i]),
as.character(ds$Abstract[i]))
}
head(v, 20)
sum(as.numeric(v))
sum(is.na(as.numeric(v)))
str(v)
for (i in 1:length(ds$Snippet)) {
v[i] <- identical(as.character(ds$Snippet[i]),
as.character(ds$Abstract[i]))
}
head(v, 20)
sum(is.na(v))
str(v)
sum(v)
rm(v)
for (i in 1:length(ds$Snippet)) {
v[i] <- identical(as.character(ds$Snippet[i]),
as.character(ds$Abstract[i]))
}
head(v, 20)
sum(is.na(v))
v <- as.logical(rep("TRUE", length(ds$Snippet)))
for (i in 1:length(ds$Snippet)) {
v[i] <- identical(as.character(ds$Snippet[i]),
as.character(ds$Abstract[i]))
}
head(v, 20)
sum(is.na(v))
str(v)
v <- as.logical(rep("FALSE", length(ds$Snippet)))
for (i in 1:length(ds$Snippet)) {
v[i] <- identical(as.character(ds$Snippet[i]),
as.character(ds$Abstract[i]))
}
head(v, 20)
sum(is.na(v))
str(v)
SUM(v)
sum(v)
length(ds$Snippet)
length(ds$Snippet) - sum(v)
which(v == FALSE)
ds$Snippet[22]
ds$Abstract[22]
identical(ds$Snippet[22], ds$Abstract[22])
identical(as.character(ds$Snippet[22]), as.character(ds$Abstract[22]))
ds$Snippet[25]
ds$Abstract[25]
