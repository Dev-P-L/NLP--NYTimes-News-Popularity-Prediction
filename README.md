# NLP-Blog-Popularity-Prediction

## I. Files

This project is comprised of 4 files:

- ds.csv contains the data,
- NLP_Popularity_Prediction_NYTimes.Rmd contains all code,
- NLP_Popularity_Prediction_NYTimes.html gives methods, insights and results in HTML format,
- NLP_Popularity_Prediction_NYTimes.oxps gives methods, insights and results in XPS format. 

<br>

## II. EXECUTIVE SUMMARY

<br>

Predicting popularity of several thousand New York Times blog articles has provided *useful insights* into latent value from unstructured data and impact of timing, classification predictors and word count.

**Natural Language Processing** has been combined with **Machine Learning**. In ML, eXtreme Gradient Boosting has proved somewhat more performing than Random Forest. Working on bootstrapped resample distributions has defeated overfitting, revealing true distributions and opening the way to an ensemble solution reaching a **94 % AUC** level on a completely insulated validation set. 

<br>

## III. TAGS

<br>

AUC, ROC, NLP, corpus, document term matrix, bag of words, ML, binary classification, eXtreme Gradient Boosting, Random Forest, bootstrapping, resamples, distributions, True Positive Rate (sensitivity), False Positive Rate, ensemble solution
